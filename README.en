
The goal of these exercises is to familiarize yourself with job submissions on
a cluster. To do that, we will use a home-made image processing tool called
"filterImage.exe" and a set of images.

===== Import the Set of Images =====
For some exercises, we will use a dataset made of high-resolution pictures.
If not done already, you must use Globus to import all files to your home
directory.

- Go to globus.computecanada.ca and log in
- Select the source endpoint. For example: intro-arc_plstonge_beluga
- Select the cluster endpoint. For example: cq-formation#name.calculquebec.cloud
- Import the "photos" folder

===== Get Workshop Exercise Material =====
Exercise material is hosted on Github, at the following address:
https://github.com/calculquebec/cq-formation-premiers-pas

If you read this README from Github, you can get these exercise files through
Globus (by importing the "exercises" folder) or by running:

   git clone https://github.com/calculquebec/cq-formation-premiers-pas.git exercises

===== Compiling filterImage.exe =====
The image processing tool must be built (i.e. compiled). To do that, you first
need to load appropriate modules. The compilation requires GNU compilers and
the BOOST library. To load these modules:

   module purge
   module load arch/avx2
   module load StdEnv
   module load gcc boost
   module list

Once all required modules are loaded, you can compile filterImage.exe with the command:

   make

This will create a file named filterImage.exe in your directory. This
executable will be used for each exercise.

===== Outline of Exercises =====
Each exercise is located in its own directory. Each exercise has a
README.en file, a submit.sh file that you will edit, and a solution.sh file.
Try exercises according to your needs:

  * 1-base
    Getting started with job submission: useful for any use case.

  * 2-sequentielles
    This exercise is useful if you run multiple serial jobs running for hours

  * 3-gnu-parallel
    This exercise is useful if you run multiple short serial jobs (<1 hour)

  * 4-lot-de-taches
    This exercise is useful if you run hundreds of jobs; you need job arrays

  * 5-tache-mpi
    This exercise is useful if you run parallel jobs with MPI on multiple nodes
